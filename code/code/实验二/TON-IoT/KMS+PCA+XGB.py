import os
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import (
    classification_report, confusion_matrix, precision_score,
    recall_score, f1_score, roc_auc_score
)
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from typing import Tuple, Dict, List

# è·¯å¾„é…ç½®
TRAIN_FILE = "D:\\workspace\\TTS-XGB\\data\\new TON-IoT\\train_no_injection_with_origidx.csv"
TEST_FILE = "D:\\workspace\\TTS-XGB\\data\\new TON-IoT\\test_full_with_injection_with_origidx.csv"
RESULTS_DIR = "D:\\workspace\\TTS-XGB\\results"
os.makedirs(RESULTS_DIR, exist_ok=True)


def create_global_label_mapping(train_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[Dict[str, int], List[str]]:
    """åˆ›å»ºå…¨å±€æ ‡ç­¾æ˜ å°„ï¼ˆè§£å†³è®­ç»ƒé›†ç±»åˆ«ä¸å…¨é—®é¢˜ï¼‰"""
    # 1. æ”¶é›†è®­ç»ƒ+æµ‹è¯•é›†çš„æ‰€æœ‰å”¯ä¸€æ ‡ç­¾
    train_labels = train_df['type'].unique()
    test_labels = test_df['type'].unique()
    all_labels = sorted(list(set(train_labels) | set(test_labels)))  # åˆå¹¶å¹¶æ’åº

    # 2. å»ºç«‹å…¨å±€è¿ç»­ç´¢å¼•æ˜ å°„ï¼ˆ0å¼€å§‹ï¼‰
    label_mapping = {label: idx for idx, label in enumerate(all_labels)}

    # æ‰“å°ç±»åˆ«åˆ†å¸ƒä¿¡æ¯
    print("\n===== ç±»åˆ«åˆ†å¸ƒè¯¦æƒ… =====")
    print(f"æ‰€æœ‰ç±»åˆ«ï¼ˆå…±{len(all_labels)}ä¸ªï¼‰: {all_labels}")
    print(f"è®­ç»ƒé›†åŒ…å«ç±»åˆ«: {sorted(train_labels)}")
    print(f"æµ‹è¯•é›†åŒ…å«ç±»åˆ«: {sorted(test_labels)}")
    print(f"è®­ç»ƒé›†ç¼ºå¤±çš„ç±»åˆ«: {[l for l in all_labels if l not in train_labels]}")
    print(f"å…¨å±€æ ‡ç­¾æ˜ å°„: {label_mapping}")

    return label_mapping, all_labels


def prepare_data(n_clusters: int = 10, pca_components: int = 10) -> Tuple[
    Tuple[np.ndarray, np.ndarray, np.ndarray],
    Tuple[np.ndarray, np.ndarray, np.ndarray],
    Dict[str, int], List[str]
]:
    """æ•°æ®é¢„å¤„ç†"""
    print("Loading data...")
    train_df = pd.read_csv(TRAIN_FILE)
    test_df = pd.read_csv(TEST_FILE)

    print(f"Train shape: {train_df.shape}, Test shape: {test_df.shape}")

    # æ•°å€¼ç‰¹å¾åˆ—è¡¨
    numeric_features = ['src_port', 'dst_port', 'duration', 'src_bytes', 'dst_bytes',
                        'missed_bytes', 'src_pkts', 'src_ip_bytes', 'dst_pkts', 'dst_ip_bytes',
                        'dns_qclass', 'dns_qtype', 'dns_rcode',
                        'http_request_body_len', 'http_response_body_len', 'http_status_code']

    # åˆ›å»ºå…¨å±€æ ‡ç­¾æ˜ å°„
    label_mapping, all_labels = create_global_label_mapping(train_df, test_df)

    # è½¬æ¢æ ‡ç­¾ä¸ºè¿ç»­ç´¢å¼•
    y_train = np.array([label_mapping[cls] for cls in train_df['type'].values])
    y_test = np.array([label_mapping[cls] for cls in test_df['type'].values])

    # åŸå§‹ç±»å‹ä¿ç•™
    type_train = train_df['type'].values
    type_test = test_df['type'].values

    # ç‰¹å¾é¢„å¤„ç†
    X_train = train_df[numeric_features].fillna(0).values.astype(np.float32)
    X_test = test_df[numeric_features].fillna(0).values.astype(np.float32)

    # Step 1: æ ‡å‡†åŒ–
    print("\nApplying StandardScaler...")
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Step 2: KMeansèšç±»
    print(f"Applying KMeans clustering (n_clusters={n_clusters})...")
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    train_clusters = kmeans.fit_predict(X_train)
    test_clusters = kmeans.predict(X_test)

    # å¢åŠ èšç±»ç‰¹å¾
    X_train_with_cluster = np.column_stack([X_train, train_clusters])
    X_test_with_cluster = np.column_stack([X_test, test_clusters])

    # Step 3: PCAé™ç»´
    print(f"Applying PCA (n_components={pca_components})...")
    pca = PCA(n_components=pca_components, random_state=42)
    X_train_pca = pca.fit_transform(X_train_with_cluster)
    X_test_pca = pca.transform(X_test_with_cluster)

    print(f"PCAè§£é‡Šæ–¹å·®å æ¯”: {pca.explained_variance_ratio_.sum():.4f}")

    return (X_train_pca, y_train, type_train), (X_test_pca, y_test, type_test), label_mapping, all_labels


def train_xgb_native(X_train: np.ndarray, y_train: np.ndarray, num_classes: int,
                     n_estimators: int = 100, max_depth: int = 3) -> xgb.Booster:
    """
    ä½¿ç”¨XGBooståŸç”Ÿæ¥å£è®­ç»ƒæ¨¡å‹ï¼ˆå½»åº•ç»•å¼€sklearnçš„ç±»åˆ«æ ¡éªŒï¼‰
    """
    print("\nTraining XGBoost model (native API)...")

    # 1. è½¬æ¢ä¸ºXGBoostçš„DMatrixæ ¼å¼ï¼ˆåŸç”Ÿæ¥å£ä¸“ç”¨ï¼‰
    dtrain = xgb.DMatrix(X_train, label=y_train)

    # 2. è®¾ç½®XGBoostå‚æ•°ï¼ˆæ— ç±»åˆ«æ ¡éªŒï¼‰
    params = {
        'objective': 'multi:softprob',  # è¾“å‡ºæ¦‚ç‡çŸ©é˜µ
        'num_class': num_classes,  # å…¨å±€ç±»åˆ«æ€»æ•°
        'max_depth': max_depth,  # æ ‘æ·±åº¦
        'eta': 0.1,  # å­¦ä¹ ç‡ï¼ˆå¯¹åº”sklearnçš„learning_rateï¼‰
        'seed': 42,  # éšæœºç§å­
        'silent': 1,  # é™é»˜æ¨¡å¼
        'eval_metric': 'mlogloss'  # å¤šåˆ†ç±»æŸå¤±
    }

    # 3. è®­ç»ƒæ¨¡å‹ï¼ˆåŸç”Ÿtrainæ¥å£ï¼Œæ— ä»»ä½•ç±»åˆ«æ ¡éªŒï¼‰
    booster = xgb.train(
        params,
        dtrain,
        num_boost_round=n_estimators,  # å¯¹åº”sklearnçš„n_estimators
        verbose_eval=False  # ä¸æ‰“å°è®­ç»ƒæ—¥å¿—
    )

    return booster


def predict_xgb_native(booster: xgb.Booster, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ä½¿ç”¨åŸç”Ÿæ¥å£é¢„æµ‹ï¼šè¿”å›ç±»åˆ«ç´¢å¼• + æ¦‚ç‡çŸ©é˜µ
    """
    dtest = xgb.DMatrix(X)
    prob_matrix = booster.predict(dtest)  # è¾“å‡ºå½¢çŠ¶: (n_samples, num_classes)
    y_pred = np.argmax(prob_matrix, axis=1)  # å–æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«
    return y_pred, prob_matrix


def main():
    # è¶…å‚æ•°
    n_clusters = int(os.environ.get("N_CLUSTERS", 10))
    pca_components = int(os.environ.get("PCA_COMPONENTS", 10))
    n_estimators = int(os.environ.get("N_ESTIMATORS", 100))
    max_depth = int(os.environ.get("MAX_DEPTH", 3))
    unknown_threshold = 0.6  # Unknownåˆ¤æ–­é˜ˆå€¼

    # æ•°æ®é¢„å¤„ç†
    (X_train, y_train, type_train), (X_test, y_test, type_test), label_mapping, all_labels = prepare_data(
        n_clusters=n_clusters,
        pca_components=pca_components
    )

    # å…¨å±€ç±»åˆ«æ€»æ•°
    num_classes = len(all_labels)
    print(f"\nç‰¹å¾ç»´åº¦: {X_train.shape[1]}, å…¨å±€ç±»åˆ«æ€»æ•°: {num_classes}")

    # è·å–å…³é”®æ ‡ç­¾ç´¢å¼•
    try:
        normal_idx = label_mapping['normal']
        injection_idx = label_mapping['injection']
    except KeyError as e:
        print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°å…³é”®æ ‡ç­¾ {e}")
        return

    # è®­ç»ƒæ¨¡å‹ï¼ˆåŸç”Ÿæ¥å£ï¼Œæ— ç±»åˆ«æ ¡éªŒï¼‰
    booster = train_xgb_native(
        X_train,
        y_train,
        num_classes=num_classes,
        n_estimators=n_estimators,
        max_depth=max_depth
    )

    # é¢„æµ‹ï¼ˆåŸç”Ÿæ¥å£ï¼‰
    print("Predicting on test set...")
    y_pred, prob_matrix = predict_xgb_native(booster, X_test)
    y_max_prob = np.max(prob_matrix, axis=1)  # æ¯ä¸ªæ ·æœ¬çš„æœ€å¤§æ¦‚ç‡

    # åº”ç”¨Unknownæ£€æµ‹ï¼ˆæ¦‚ç‡ä½äºé˜ˆå€¼çš„è§†ä¸ºUnknownï¼‰
    final_pred = np.where(y_max_prob < unknown_threshold, -1, y_pred)  # -1è¡¨ç¤ºUnknown

    # ============== A) äºŒåˆ†ç±»è¯„ä¼°ï¼ˆnormal vs å…¶ä»–ï¼‰ ==============
    print("\n===== A) äºŒåˆ†ç±»è¯„ä¼° (normal vs å…¶ä»–) =====")
    # çœŸå®æ ‡ç­¾ï¼šnormal=0ï¼Œå…¶ä»–=1
    y_binary_true = np.where(type_test == 'normal', 0, 1)
    # é¢„æµ‹æ ‡ç­¾ï¼šnormal=0ï¼Œå…¶ä»–=1ï¼ˆåŒ…æ‹¬Unknownï¼‰
    y_binary_pred = np.where((final_pred == normal_idx) & (y_max_prob >= unknown_threshold), 0, 1)

    # è®¡ç®—æŒ‡æ ‡
    binary_precision = precision_score(y_binary_true, y_binary_pred, zero_division=0)
    binary_recall = recall_score(y_binary_true, y_binary_pred, zero_division=0)
    binary_f1 = f1_score(y_binary_true, y_binary_pred, zero_division=0)

    # è®¡ç®—AUROCï¼ˆä½¿ç”¨normalç±»çš„æ¦‚ç‡ä½œä¸ºè¯„åˆ†ï¼‰
    normal_prob = prob_matrix[:, normal_idx] if normal_idx < prob_matrix.shape[1] else np.zeros(len(y_test))
    binary_auc = roc_auc_score(y_binary_true, 1 - normal_prob)  # 1-normalæ¦‚ç‡ä½œä¸ºå¼‚å¸¸åˆ†æ•°

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_binary_true, y_binary_pred)

    # æ‰“å°ç»“æœ
    print(f"ç²¾ç¡®ç‡ (Precision): {binary_precision:.4f}")
    print(f"å¬å›ç‡ (Recall): {binary_recall:.4f}")
    print(f"F1åˆ†æ•°: {binary_f1:.4f}")
    print(f"AUROC: {binary_auc:.4f}")
    print("æ··æ·†çŸ©é˜µ:")
    print(cm)
    print("æ··æ·†çŸ©é˜µè§£é‡Š:")
    print(f"TN: {cm[0, 0]} (æ­£å¸¸è¢«æ­£ç¡®é¢„æµ‹ä¸ºæ­£å¸¸)")
    print(f"FP: {cm[0, 1]} (æ­£å¸¸è¢«é¢„æµ‹ä¸ºå¼‚å¸¸)")
    print(f"FN: {cm[1, 0]} (å¼‚å¸¸è¢«é¢„æµ‹ä¸ºæ­£å¸¸)")
    print(f"TP: {cm[1, 1]} (å¼‚å¸¸è¢«æ­£ç¡®é¢„æµ‹ä¸ºå¼‚å¸¸)")

    # ============== B) å·²çŸ¥æ”»å‡»å¤šåˆ†ç±»è¯„ä¼°ï¼ˆé™¤injectionï¼‰ ==============
    print("\n===== B) å·²çŸ¥æ”»å‡»å¤šåˆ†ç±»è¯„ä¼° (é™¤injection) =====")
    # ç­›é€‰å·²çŸ¥ç±»æ ·æœ¬ï¼ˆéinjectionä¸”éUnknownï¼‰
    known_mask = (type_test != 'injection') & (final_pred != -1)
    known_count = np.sum(known_mask)
    total_known_samples = np.sum(type_test != 'injection')

    if known_count > 0:
        # å·²çŸ¥ç±»çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
        y_known_true = y_test[known_mask]
        y_known_pred = final_pred[known_mask]

        # è¿‡æ»¤æ‰injectionç›¸å…³æ ‡ç­¾
        valid_mask = ~np.isin(y_known_true, injection_idx)
        y_known_true = y_known_true[valid_mask]
        y_known_pred = y_known_pred[valid_mask]

        if len(y_known_true) > 0:
            macro_f1_known = f1_score(y_known_true, y_known_pred, average='macro', zero_division=0)
            coverage_known = known_count / total_known_samples if total_known_samples > 0 else 0.0

            print(f"Macro-F1 (å·²çŸ¥ç±»): {macro_f1_known:.4f}")
            print(f"è¦†ç›–ç‡ (Coverage): {coverage_known:.4f} (â‰¥0.90ä¸ºè¾¾æ ‡)")
        else:
            print("æ— æœ‰æ•ˆå·²çŸ¥ç±»æ ·æœ¬ç”¨äºè¯„ä¼°")
    else:
        print("æ— å·²çŸ¥ç±»æ ·æœ¬ç”¨äºè¯„ä¼°")

    # ============== C) Unknown(injection) å»å‘ç»Ÿè®¡ + Unknown F1 ==============
    print("\n===== C) Unknown(injection) åˆ†æ =====")
    # ç­›é€‰injectionæ ·æœ¬
    injection_mask = (type_test == 'injection')
    total_injection = np.sum(injection_mask)

    if total_injection == 0:
        print("æµ‹è¯•é›†ä¸­æœªæ‰¾åˆ°injectionæ ·æœ¬")
    else:
        # injectionæ ·æœ¬çš„é¢„æµ‹ç»“æœ
        injection_pred = final_pred[injection_mask]
        injection_max_prob = y_max_prob[injection_mask]

        # ç»Ÿè®¡å»å‘
        pred_normal = np.sum((injection_pred == normal_idx) & (injection_max_prob >= unknown_threshold))
        pred_unknown = np.sum(injection_pred == -1)  # è¢«è¯†åˆ«ä¸ºUnknown
        pred_other_attack = total_injection - pred_normal - pred_unknown  # è¢«è¯†åˆ«ä¸ºå…¶ä»–å·²çŸ¥æ”»å‡»

        # è®¡ç®—Unknownæ£€æµ‹çš„F1åˆ†æ•°
        # çœŸå®æ ‡ç­¾ï¼šinjection=1ï¼ˆè§†ä¸ºUnknownï¼‰ï¼Œå…¶ä»–=0
        y_unknown_true = np.where(type_test == 'injection', 1, 0)
        # é¢„æµ‹æ ‡ç­¾ï¼šè¢«è¯†åˆ«ä¸ºUnknown=1ï¼Œå…¶ä»–=0
        y_unknown_pred = np.where(final_pred == -1, 1, 0)

        unknown_precision = precision_score(y_unknown_true, y_unknown_pred, zero_division=0)
        unknown_recall = recall_score(y_unknown_true, y_unknown_pred, zero_division=0)
        unknown_f1 = f1_score(y_unknown_true, y_unknown_pred, zero_division=0)

        # æ‰“å°ç»“æœ
        print(f"Injectionæ ·æœ¬æ€»æ•°: {total_injection}")
        print(f"  â†’ è¢«é¢„æµ‹ä¸ºNormal: {pred_normal} ({pred_normal / total_injection * 100:.2f}%)")
        print(f"  â†’ è¢«é¢„æµ‹ä¸ºUnknown: {pred_unknown} ({pred_unknown / total_injection * 100:.2f}%)")
        print(f"  â†’ è¢«é¢„æµ‹ä¸ºå…¶ä»–æ”»å‡»: {pred_other_attack} ({pred_other_attack / total_injection * 100:.2f}%)")
        print(f"\nUnknownæ£€æµ‹F1åˆ†æ•°: {unknown_f1:.4f}")
        print(f"Unknownæ£€æµ‹ç²¾ç¡®ç‡: {unknown_precision:.4f}")
        print(f"Unknownæ£€æµ‹å¬å›ç‡: {unknown_recall:.4f}")

    # ä¿å­˜ç»“æœ
    print("\nğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜è·¯å¾„:")
    report_path = os.path.join(RESULTS_DIR, "xgb_model_complete_report.txt")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("===== å®Œæ•´è¯„ä¼°æŠ¥å‘Š =====\n\n")

        # ä¿å­˜äºŒåˆ†ç±»ç»“æœ
        f.write("A) äºŒåˆ†ç±»è¯„ä¼° (normal vs å…¶ä»–)\n")
        f.write(f"ç²¾ç¡®ç‡: {binary_precision:.4f}\n")
        f.write(f"å¬å›ç‡: {binary_recall:.4f}\n")
        f.write(f"F1åˆ†æ•°: {binary_f1:.4f}\n")
        f.write(f"AUROC: {binary_auc:.4f}\n")
        f.write("æ··æ·†çŸ©é˜µ:\n")
        f.write(f"{cm}\n\n")

        # ä¿å­˜å·²çŸ¥ç±»å¤šåˆ†ç±»ç»“æœ
        f.write("B) å·²çŸ¥æ”»å‡»å¤šåˆ†ç±»è¯„ä¼° (é™¤injection)\n")
        if known_count > 0 and len(y_known_true) > 0:
            f.write(f"Macro-F1 (å·²çŸ¥ç±»): {macro_f1_known:.4f}\n")
            f.write(f"è¦†ç›–ç‡: {coverage_known:.4f}\n\n")
        else:
            f.write("æ— æœ‰æ•ˆè¯„ä¼°æ•°æ®\n\n")

        # ä¿å­˜Unknownåˆ†æç»“æœ
        f.write("C) Unknown(injection) åˆ†æ\n")
        if total_injection > 0:
            f.write(f"Injectionæ ·æœ¬æ€»æ•°: {total_injection}\n")
            f.write(f"â†’ Normal: {pred_normal} ({pred_normal / total_injection * 100:.2f}%)\n")
            f.write(f"â†’ Unknown: {pred_unknown} ({pred_unknown / total_injection * 100:.2f}%)\n")
            f.write(f"â†’ å…¶ä»–æ”»å‡»: {pred_other_attack} ({pred_other_attack / total_injection * 100:.2f}%)\n")
            f.write(f"Unknown F1åˆ†æ•°: {unknown_f1:.4f}\n")
        else:
            f.write("æµ‹è¯•é›†ä¸­æœªæ‰¾åˆ°injectionæ ·æœ¬\n")

    print(f"- å®Œæ•´è¯„ä¼°æŠ¥å‘Š: {report_path}")

    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(RESULTS_DIR, "xgb_model.model")
    booster.save_model(model_path)
    print(f"- æ¨¡å‹æ–‡ä»¶: {model_path}")


if __name__ == "__main__":
    main()