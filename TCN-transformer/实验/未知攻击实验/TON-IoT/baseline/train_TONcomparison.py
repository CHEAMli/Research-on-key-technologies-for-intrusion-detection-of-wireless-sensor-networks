# -*- coding: utf-8 -*-
"""TON-IoT å®éªŒäºŒï¼ˆUnknown / æ‹’è¯†ï¼‰â€”â€” å¯¹ç…§ç»„ Baseline é¢„å¤„ç†

ä½ å½“å‰çš„å®éªŒè®¾å®šï¼ˆä¸ä½ åœ¨ WSN-DS å®éªŒäºŒä¸€è‡´ï¼‰ï¼š
  - Unknown æ”»å‡»ï¼šInjection
  - æ•°æ®é›†ï¼šä½ å·²ç»ç¦»çº¿åˆ’åˆ†å¥½çš„ train / val / testï¼ˆCSVï¼‰
      * trainã€valï¼šå·²åˆ é™¤ injection
      * testï¼šåŒ…å« injectionï¼ˆå…¨é‡ï¼‰

è„šæœ¬ä¸€æ¬¡è¿è¡Œè¾“å‡ºï¼š
  1) Stage-1 äºŒåˆ†ç±»ï¼ˆNormal vs Attackï¼‰è¯„ä¼° + 2Ã—2 æ··æ·†çŸ©é˜µ
  2) Stage-2 æ”»å‡»å¤šåˆ†ç±»ï¼ˆåªåœ¨ Known Attack ä¸Šè®­ç»ƒ/è¯„ä¼°ï¼‰
  3) Unknown(Injection) æ‹’è¯†è¯„ä¼°ï¼š
       - Injection è¢«åˆ¤ä¸º Normal / Unknown / å…¶ä»– Known æ”»å‡» çš„æ•°é‡ä¸æ¯”ä¾‹
       - Unknown Precision / Recall / F1ï¼ˆæŠŠ Unknown è§†ä¸ºâ€œæ­£ç±»â€ï¼‰
       - Known-only Macro-F1 ä¸ Coverageï¼ˆåªåœ¨æœªè¢«æ‹’è¯†çš„ Known Attack ä¸Šç®—å¤šåˆ†ç±»ï¼‰

æ³¨æ„ï¼š
  - è¿™é‡Œçš„â€œUnknownâ€ä¸æ˜¯æ–°ç±»åˆ«å‚ä¸è®­ç»ƒï¼Œè€Œæ˜¯é€šè¿‡ Stage-2 çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆmax softmax < tauï¼‰è¿›è¡Œæ‹’è¯†ã€‚
  - tau é»˜è®¤ç”¨ val(known attack) è‡ªåŠ¨æ ‡å®šï¼šä¿æŒçº¦ 95% çš„ known attack ä¸è¢«æ‹’è¯†ã€‚

ä½¿ç”¨ï¼š
  1) åªæ”¹ CFG.train_csv / CFG.val_csv / CFG.test_csv ä¸ºä½ æœ¬åœ°è·¯å¾„
  2) python train_TONcomparison_exp2_unknown_injection.py
"""

import random
from dataclasses import dataclass
from typing import List, Tuple, Dict, Optional

import numpy as np
import pandas as pd

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction import FeatureHasher
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, classification_report
)

# ä½ çš„æ¨¡å‹æ–‡ä»¶ï¼šä¼˜å…ˆä½¿ç”¨ä½ æä¾›çš„ model_TONcomparison.py
from model_TONcomparison import AnomalyDetectionModel  # type: ignore
# =========================
# 0) é…ç½®
# =========================
@dataclass
class CFG:
    # ====== ä½ çš„ç¦»çº¿åˆ’åˆ†è·¯å¾„ï¼ˆä½ è‡ªå·±å¡«ï¼‰ ======
    train_csv: str = r"C:\Users\yeqing\PycharmProjects\pythonProject\Train_Test_datasets\Train_Test_Network_dataset\train_no_injection_with_origidx.csv"
    val_csv: str = r"C:\Users\yeqing\PycharmProjects\pythonProject\Train_Test_datasets\Train_Test_Network_dataset\val_no_injection_with_origidx.csv"
    test_csv: str = r"C:\Users\yeqing\PycharmProjects\pythonProject\Train_Test_datasets\Train_Test_Network_dataset\test_full_with_injection_with_origidx.csv"


    # ====== Unknown è®¾ç½® ======
    unknown_token: str = "injection"   # type åˆ—é‡Œ Injection çš„åå­—ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰

    # Feature encoding (baseline)
    hash_dim: int = 8
    drop_text_cols: bool = True

    # Windowing
    win: int = 64
    stride: int = 8
    window_label_mode: str = "last"  # "majority" / "last" / "any_attack"

    # Train
    seed: int = 42
    batch_size: int = 256
    epochs_bin: int = 20
    epochs_type: int = 20
    lr: float = 1e-3
    weight_decay: float = 1e-5
    device: str = "cuda" if torch.cuda.is_available() else "cpu"

    # Model
    model_dim: int = 128
    cross_attn_layers: int = 2
    tcn_layers: int = 2
    transformer_layers: int = 2
    nheads: int = 8
    dropout: float = 0.1

    # Stage-2
    init_from_stage1: bool = True

    # Decision thresholds
    attack_prob_thr: float = 0.5         # Stage-1ï¼šåˆ¤ Attack çš„é˜ˆå€¼
    unknown_tau: Optional[float] = None  # Stage-2ï¼šæ‹’è¯†é˜ˆå€¼ï¼ˆNone=è‡ªåŠ¨æ ‡å®šï¼‰
    known_keep_coverage: float = 0.90    # è‡ªåŠ¨æ ‡å®š tauï¼šå°½é‡è®© known attack è‡³å°‘ä¿ç•™è¿™ä¹ˆå¤š


def seed_all(seed: int):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


# =========================
# 1) TON Baseline é¢„å¤„ç†ï¼ˆåªåšç‰¹å¾ï¼Œä¸æºæ‚æ ‡ç­¾ï¼‰
# =========================
BOOLISH_COLS = [
    "dns_AA", "dns_RD", "dns_RA", "dns_rejected",
    "ssl_resumed", "ssl_established",
    "weird_notice",
]

DASH_INT_COLS = [
    "http_trans_depth", "weird_addl",
]

LOW_CAT_COLS = [
    "proto", "service", "conn_state",
    "dns_qclass", "dns_qtype", "dns_rcode",
    "ssl_version", "ssl_cipher",
    "http_method", "http_version",
    "weird_name",
]

HIGH_CAT_COLS = [
    "src_ip", "dst_ip",
    "dns_query",
    "http_uri",
    "http_user_agent",
    "ssl_subject",
    "ssl_issuer",
    "http_orig_mime_types",
    "http_resp_mime_types",
]


def _tf_to_int(s: pd.Series) -> pd.Series:
    return (
        s.fillna("-")
        .astype(str)
        .map({"T": 1, "F": 0, "-": 0})
        .fillna(0)
        .astype(np.int8)
    )


def _dashnum_to_int(s: pd.Series) -> pd.Series:
    return (
        s.fillna("-")
        .astype(str)
        .replace("-", "0")
        .astype(np.int32)
    )


def _hash_col(series: pd.Series, n_features: int, prefix: str) -> pd.DataFrame:
    hasher = FeatureHasher(n_features=n_features, input_type="string", alternate_sign=False)
    tokens = [[f"{prefix}={v}"] for v in series.fillna("missing").astype(str).tolist()]
    mat = hasher.transform(tokens).toarray().astype(np.float32)
    return pd.DataFrame(mat, columns=[f"{prefix}_h{i}" for i in range(n_features)])


def preprocess_ton_features(df: pd.DataFrame, cfg: CFG) -> Tuple[pd.DataFrame, List[str], List[str]]:
    """è¿”å›ï¼šX_dfã€å…¨éƒ¨ç‰¹å¾åˆ—åã€è¿ç»­æ•°å€¼åˆ—åï¼ˆç”¨äºä»…æ ‡å‡†åŒ–è¿™äº›åˆ—ï¼‰"""
    df = df.copy()

    # 1) boolish / dash-int
    for c in BOOLISH_COLS:
        if c in df.columns:
            df[c] = _tf_to_int(df[c])
    for c in DASH_INT_COLS:
        if c in df.columns:
            df[c] = _dashnum_to_int(df[c])

    # 2) low-card one-hot
    low_cat = [c for c in LOW_CAT_COLS if c in df.columns]
    for c in low_cat:
        df[c] = df[c].fillna("missing").astype(str)
    df_low = pd.get_dummies(df[low_cat], prefix=low_cat, dtype=np.uint8) if low_cat else pd.DataFrame(index=df.index)

    # 3) high-card hashing
    high_cat = [c for c in HIGH_CAT_COLS if c in df.columns]
    if cfg.drop_text_cols:
        # è¿™äº›åˆ—æç¨€ç–ä¸”å¯¹ä½ æ¨¡å‹ä¸å‹å¥½ï¼Œé»˜è®¤å»æ‰
        high_cat = [c for c in high_cat if c not in ["dns_query", "http_uri", "http_user_agent"]]
    df_hash_list = [_hash_col(df[c], cfg.hash_dim, c) for c in high_cat]
    df_hash = pd.concat(df_hash_list, axis=1) if df_hash_list else pd.DataFrame(index=df.index)

    # 4) continuous numeric
    ignore = set(low_cat + high_cat + ["label", "type"])
    cont_cols = [c for c in df.columns if c not in ignore]
    cont = df[cont_cols].copy()
    for c in cont.columns:
        cont[c] = pd.to_numeric(cont[c], errors="coerce")
    cont = cont.fillna(0.0).astype(np.float32)

    X_df = pd.concat([cont, df_low, df_hash], axis=1)
    return X_df, list(X_df.columns), list(cont.columns)


# =========================
# 2) æ»‘çª—ï¼ˆåŒæ—¶äº§å‡º binary label + attack type labelï¼‰
# =========================

def window_label_from_seg(y_seg: np.ndarray, mode: str, normal_id: int = 0) -> int:
    if mode == "last":
        return int(y_seg[-1])
    if mode == "any_attack":
        return int(1 if np.any(y_seg != normal_id) else normal_id)
    # majority
    vals, cnt = np.unique(y_seg, return_counts=True)
    return int(vals[np.argmax(cnt)])


def make_windows_two_labels(
    X: np.ndarray,
    y_bin: np.ndarray,
    y_type_str: np.ndarray,
    cfg: CFG,
    attack_type_to_idx: Dict[str, int],
    normal_token: str = "normal",
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """è¿”å›ï¼šXw [Nw,W,D], yb_w [Nw], yt_w [Nw](known type idx or -1), tlast_w[str]

    è¯´æ˜ï¼š
      - yt_w=-1 è¡¨ç¤ºï¼šéæ”»å‡»çª—å£ or Unknown æ”»å‡»ï¼ˆå¦‚ injectionï¼‰
      - tlast_w ä¿å­˜ last-step çš„ type å­—ç¬¦ä¸²ï¼Œç”¨äºç»Ÿè®¡ Injectionâ†’XXX
    """
    N, D = X.shape
    if N < cfg.win:
        raise ValueError(f"Too few rows ({N}) for win={cfg.win}")

    xs, ybs, yts, tlasts = [], [], [], []
    for i in range(0, N - cfg.win + 1, cfg.stride):
        seg_bin = y_bin[i:i + cfg.win]
        yb = window_label_from_seg(seg_bin, cfg.window_label_mode, normal_id=0)

        t_last = str(y_type_str[i + cfg.win - 1])
        tlasts.append(t_last)

        if yb == 1:
            if t_last.lower() == normal_token:
                yt = -1
            else:
                yt = int(attack_type_to_idx.get(t_last, -1))
        else:
            yt = -1

        xs.append(X[i:i + cfg.win])
        ybs.append(yb)
        yts.append(yt)

    return (
        np.asarray(xs, dtype=np.float32),
        np.asarray(ybs, dtype=np.int64),
        np.asarray(yts, dtype=np.int64),
        np.asarray(tlasts, dtype=object),
    )


class WindowDataset(Dataset):
    def __init__(self, Xw: np.ndarray, yw: np.ndarray):
        self.Xw = torch.from_numpy(Xw)
        self.yw = torch.from_numpy(yw)

    def __len__(self):
        return self.Xw.shape[0]

    def __getitem__(self, idx):
        return self.Xw[idx], self.yw[idx]


# =========================
# 3) è¯„ä¼°ï¼ˆStage-1 äºŒåˆ†ç±»ï¼‰
# =========================
@torch.no_grad()
def predict_binary(model: nn.Module, loader: DataLoader, device: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    model.eval()
    ys, probs, preds = [], [], []
    for xb, yb in loader:
        xb = xb.to(device)
        logits = model(xb)
        prob_attack = torch.softmax(logits, dim=1)[:, 1]
        ys.append(yb.numpy())
        probs.append(prob_attack.detach().cpu().numpy())
        preds.append((prob_attack >= 0.5).long().cpu().numpy())
    y = np.concatenate(ys).astype(np.int64)
    prob = np.concatenate(probs).astype(np.float32)
    pred = np.concatenate(preds).astype(np.int64)
    return y, pred, prob


def eval_binary_from_pred(y: np.ndarray, p: np.ndarray, prob: np.ndarray) -> Dict[str, float]:
    cm = confusion_matrix(y, p, labels=[0, 1])
    tn, fp, fn, tp = [int(x) for x in cm.ravel()]
    out = {
        "acc": float(accuracy_score(y, p)),
        "p": float(precision_score(y, p, zero_division=0)),
        "r": float(recall_score(y, p, zero_division=0)),
        "f1": float(f1_score(y, p, zero_division=0)),
        "tn": tn, "fp": fp, "fn": fn, "tp": tp,
    }
    try:
        out["auroc"] = float(roc_auc_score(y, prob))
    except Exception:
        out["auroc"] = float("nan")
    return out


# =========================
# 4) è¯„ä¼°ï¼ˆStage-2 å¤šåˆ†ç±» + Unknown æ‹’è¯†ï¼‰
# =========================
@torch.no_grad()
def predict_multiclass(model: nn.Module, Xw: np.ndarray, device: str, batch_size: int) -> Tuple[np.ndarray, np.ndarray]:
    """è¿”å›ï¼šmaxprob, pred_classï¼ˆargmaxï¼‰"""
    model.eval()
    maxps, preds = [], []
    for i in range(0, len(Xw), batch_size):
        xb = torch.from_numpy(Xw[i:i + batch_size]).to(device)
        logits = model(xb)
        prob = torch.softmax(logits, dim=1)
        maxp, pred = prob.max(dim=1)
        maxps.append(maxp.detach().cpu().numpy())
        preds.append(pred.detach().cpu().numpy())
    return np.concatenate(maxps), np.concatenate(preds)


def compute_unknown_tau_from_val(maxp_val: np.ndarray, keep_coverage: float) -> float:
    """è®© known attack å¤§çº¦ keep_coverage çš„çª—å£ä¸è¢«æ‹’è¯†ï¼štau = quantile(maxp, 1-keep)."""
    keep_coverage = float(np.clip(keep_coverage, 0.5, 0.999))
    q = 1.0 - keep_coverage
    return float(np.quantile(maxp_val, q))


def balanced_weights(y: np.ndarray, K: int) -> np.ndarray:
    """balanced æƒé‡ï¼šw_c = N/(K*count_c)ï¼Œç¼ºå¤±ç±» weight=1"""
    y = y.astype(np.int64)
    counts = np.bincount(y, minlength=K).astype(np.float64)
    N = counts.sum()
    w = np.ones(K, dtype=np.float32)
    for c in range(K):
        if counts[c] > 0:
            w[c] = float(N / (K * counts[c]))
    return w


# =========================
# 5) è®­ç»ƒ
# =========================

def build_model(cfg: CFG, feature_dim: int, num_classes: int) -> nn.Module:
    return AnomalyDetectionModel(
        feature_dim=feature_dim,
        num_classes=num_classes,
        cross_attn_layers=cfg.cross_attn_layers,
        model_dim=cfg.model_dim,
        tcn_layers=cfg.tcn_layers,
        transformer_layers=cfg.transformer_layers,
        nheads=cfg.nheads,
        dropout=cfg.dropout,
        max_len=cfg.win,
    )


def train_loop(
    model: nn.Module,
    train_loader: DataLoader,
    val_loader: DataLoader,
    cfg: CFG,
    epochs: int,
    criterion: nn.Module,
    eval_fn,
    best_path: str,
    best_key: str,
):
    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)
    best = -1.0
    for ep in range(1, epochs + 1):
        model.train()
        total = 0.0
        for xb, yb in train_loader:
            xb = xb.to(cfg.device)
            yb = yb.to(cfg.device)
            opt.zero_grad(set_to_none=True)
            logits = model(xb)
            loss = criterion(logits, yb)
            loss.backward()
            nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            opt.step()
            total += float(loss.item())
        avg_loss = total / max(1, len(train_loader))
        val = eval_fn(model, val_loader)
        score = float(val[best_key])
        print(f"Epoch {ep:02d} | loss={avg_loss:.4f} | VAL {best_key}={score:.4f}")
        if score > best:
            best = score
            torch.save(model.state_dict(), best_path)
    model.load_state_dict(torch.load(best_path, map_location=cfg.device,weights_only=True))


def main():
    cfg = CFG()
    seed_all(cfg.seed)
    assert cfg.window_label_mode in ("majority", "last", "any_attack")

    print("ğŸš€ Load offline split CSVs")
    print("  train:", cfg.train_csv)
    print("  val  :", cfg.val_csv)
    print("  test :", cfg.test_csv)

    df_tr = pd.read_csv(cfg.train_csv, low_memory=False)
    df_va = pd.read_csv(cfg.val_csv, low_memory=False)
    df_te = pd.read_csv(cfg.test_csv, low_memory=False)

    # ===== å¿…é¡»ï¼šæŒ‰ orig_idx æ¢å¤åŸå§‹é¡ºåºï¼ˆæ»‘çª—å‰ï¼‰=====
    for name, d in [("train", df_tr), ("val", df_va), ("test", df_te)]:
        if "orig_idx" not in d.columns:
            raise ValueError(f"{name} ç¼ºå°‘ orig_idx åˆ—ï¼Œè¯·ä½¿ç”¨ *_with_origidx.csv")
        d.sort_values("orig_idx", inplace=True)
        d.reset_index(drop=True, inplace=True)

    for name, df in [("train", df_tr), ("val", df_va), ("test", df_te)]:
        if "label" not in df.columns or "type" not in df.columns:
            raise ValueError(f"{name} ç¼ºå°‘ label/type åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")

    print(f"Rows: train={len(df_tr)} val={len(df_va)} test={len(df_te)}")

    # ===== Attack typesï¼šåªç”¨ train+valï¼ˆå› ä¸º injection å·²ä»è¿™é‡Œåˆ é™¤ï¼‰ =====
    type_trva = pd.concat([df_tr[["type"]], df_va[["type"]]], axis=0)["type"].fillna("missing").astype(str).to_numpy()
    is_normal = np.char.lower(type_trva.astype(str)) == "normal"
    attack_type_set = sorted(set(type_trva[~is_normal].tolist()))

    # å¦‚æœä½ æ‹…å¿ƒ injection æ²¡åˆ å¹²å‡€ï¼Œè¿™é‡Œå¼ºåˆ¶ç§»é™¤ä¸€æ¬¡
    attack_type_set = [t for t in attack_type_set if t.lower() != cfg.unknown_token.lower()]

    attack_type_to_idx = {t: i for i, t in enumerate(attack_type_set)}
    print(f"[Known attack types] K={len(attack_type_set)} (exclude 'normal' and unknown='{cfg.unknown_token}')")

    # ===== Featuresï¼šä¸ºä¿è¯ one-hot åˆ—ä¸€è‡´ï¼Œè¿™é‡Œå¯¹ train+val+test ä¸€èµ·åšç‰¹å¾å±•å¼€ï¼ˆä¸ä½¿ç”¨æ ‡ç­¾ï¼‰ =====
    df_all = pd.concat([df_tr, df_va, df_te], axis=0, ignore_index=True)

    X_df, feature_cols, cont_cols = preprocess_ton_features(df_all, cfg)
    X_all = X_df.to_numpy().astype(np.float32)

    n_tr = len(df_tr)
    n_va = len(df_va)
    idx_tr = np.arange(0, n_tr)
    idx_va = np.arange(n_tr, n_tr + n_va)
    idx_te = np.arange(n_tr + n_va, n_tr + n_va + len(df_te))

    # ===== åªç”¨ train æ‹Ÿåˆ scalerï¼ˆä»…è¿ç»­åˆ—ï¼‰ =====
    cont_idx = [feature_cols.index(c) for c in cont_cols]
    scaler = StandardScaler()
    scaler.fit(X_all[idx_tr][:, cont_idx])
    X_all[:, cont_idx] = scaler.transform(X_all[:, cont_idx]).astype(np.float32)

    # ===== labels =====
    y_bin_all = df_all["label"].astype(int).to_numpy()
    type_all = df_all["type"].fillna("missing").astype(str).to_numpy()

    # ===== windows =====
    Xw_tr, yb_tr, yt_tr, tlast_tr = make_windows_two_labels(X_all[idx_tr], y_bin_all[idx_tr], type_all[idx_tr], cfg, attack_type_to_idx)
    Xw_va, yb_va, yt_va, tlast_va = make_windows_two_labels(X_all[idx_va], y_bin_all[idx_va], type_all[idx_va], cfg, attack_type_to_idx)
    Xw_te, yb_te, yt_te, tlast_te = make_windows_two_labels(X_all[idx_te], y_bin_all[idx_te], type_all[idx_te], cfg, attack_type_to_idx)

    print(f"[Features] dim={len(feature_cols)} | cont={len(cont_cols)} | hash_dim={cfg.hash_dim} | drop_text={cfg.drop_text_cols}")
    print(f"[Window] win={cfg.win} stride={cfg.stride} label_mode={cfg.window_label_mode}")
    print(f"[Windows] train={Xw_tr.shape} val={Xw_va.shape} test={Xw_te.shape}")
    print("[Binary window dist][train]", {int(k): int(v) for k, v in zip(*np.unique(yb_tr, return_counts=True))})

    # =========================
    # Stage-1: Binary Detector
    # =========================
    feature_dim = Xw_tr.shape[2]
    model_bin = build_model(cfg, feature_dim, num_classes=2).to(cfg.device)
    print("[Stage-1] Model params:", sum(p.numel() for p in model_bin.parameters()))

    w_bin = balanced_weights(yb_tr, K=2)
    crit_bin = nn.CrossEntropyLoss(weight=torch.tensor(w_bin, dtype=torch.float32, device=cfg.device))

    dl_tr_bin = DataLoader(WindowDataset(Xw_tr, yb_tr), batch_size=cfg.batch_size, shuffle=True, num_workers=0)
    dl_va_bin = DataLoader(WindowDataset(Xw_va, yb_va), batch_size=cfg.batch_size, shuffle=False, num_workers=0)
    dl_te_bin = DataLoader(WindowDataset(Xw_te, yb_te), batch_size=cfg.batch_size, shuffle=False, num_workers=0)

    best_bin = "best_ton_exp2_stage1_binary.pt"
    train_loop(
        model_bin,
        dl_tr_bin,
        dl_va_bin,
        cfg,
        epochs=cfg.epochs_bin,
        criterion=crit_bin,
        eval_fn=lambda m, l: eval_binary_from_pred(*predict_binary(m, l, cfg.device)),
        best_path=best_bin,
        best_key="f1",
    )

    # test stage-1
    y_te_bin, prob_te_attack, pred_te_attack_05 = predict_binary(model_bin, dl_te_bin, cfg.device)
    pred_te_attack = (prob_te_attack >= cfg.attack_prob_thr).astype(np.int64)
    te_bin = eval_binary_from_pred(y_te_bin, pred_te_attack, prob_te_attack)
    print("\n[TEST][Stage-1 Binary]")
    print(te_bin)
    print(f"ConfusionMatrix [[TN FP],[FN TP]] = [[{te_bin['tn']} {te_bin['fp']}],[{te_bin['fn']} {te_bin['tp']}]]")
    print(f"[Stage-1] attack_prob_thr={cfg.attack_prob_thr:.2f}")

    # =========================
    # Stage-2: Known Attack Type Classifier
    # =========================
    def filter_known_attack(Xw, yt, yb, tlast):
        m = (yb == 1) & (yt >= 0)
        return Xw[m], yt[m], tlast[m]

    Xw_tr_k, yt_tr_k, _ = filter_known_attack(Xw_tr, yt_tr, yb_tr, tlast_tr)
    Xw_va_k, yt_va_k, _ = filter_known_attack(Xw_va, yt_va, yb_va, tlast_va)
    Xw_te_k, yt_te_k, _ = filter_known_attack(Xw_te, yt_te, yb_te, tlast_te)

    K_attack = len(attack_type_set)
    print(f"\n[Stage-2] Known-Attack windows only: train={len(yt_tr_k)} val={len(yt_va_k)} test={len(yt_te_k)} | K={K_attack}")

    if len(yt_tr_k) == 0 or K_attack == 0:
        print("[WARN] No known attack windows or no known attack types found. Stage-2 skipped.")
        return

    model_type = build_model(cfg, feature_dim, num_classes=K_attack).to(cfg.device)

    # init from stage-1 (skip fc)
    if cfg.init_from_stage1:
        sd = torch.load(best_bin, map_location="cpu",weights_only=True)
        for k in list(sd.keys()):
            if k.startswith("fc."):
                sd.pop(k)
        missing, unexpected = model_type.load_state_dict(sd, strict=False)
        print("[Stage-2] init_from_stage1=True | missing:", len(missing), "unexpected:", len(unexpected))

    w_type = balanced_weights(yt_tr_k, K=K_attack)
    crit_type = nn.CrossEntropyLoss(weight=torch.tensor(w_type, dtype=torch.float32, device=cfg.device))

    dl_tr_type = DataLoader(WindowDataset(Xw_tr_k, yt_tr_k), batch_size=cfg.batch_size, shuffle=True, num_workers=0)
    dl_va_type = DataLoader(WindowDataset(Xw_va_k, yt_va_k), batch_size=cfg.batch_size, shuffle=False, num_workers=0)

    def eval_known_type(model: nn.Module, loader: DataLoader) -> Dict[str, float]:
        model.eval()
        ys, ps = [], []
        for xb, yb in loader:
            xb = xb.to(cfg.device)
            logits = model(xb)
            pred = logits.argmax(dim=1)
            ys.append(yb.numpy())
            ps.append(pred.cpu().numpy())
        y = np.concatenate(ys)
        p = np.concatenate(ps)
        out = {
            "acc": float(accuracy_score(y, p)),
            "macro_f1": float(f1_score(y, p, average="macro", labels=list(range(K_attack)), zero_division=0)),
            "weighted_f1": float(f1_score(y, p, average="weighted", labels=list(range(K_attack)), zero_division=0)),
        }
        return out

    best_type = "best_ton_exp2_stage2_known_attack_types.pt"
    train_loop(
        model_type,
        dl_tr_type,
        dl_va_type,
        cfg,
        epochs=cfg.epochs_type,
        criterion=crit_type,
        eval_fn=lambda m, l: eval_known_type(m, l),
        best_path=best_type,
        best_key="macro_f1",
    )

    # ========== Stage-2: åœ¨ val ä¸Šè‡ªåŠ¨æ ‡å®š unknown tau ==========
    maxp_va, pred_va = predict_multiclass(model_type, Xw_va_k, cfg.device, cfg.batch_size)
    if cfg.unknown_tau is None:
        tau = compute_unknown_tau_from_val(maxp_va, keep_coverage=cfg.known_keep_coverage)
        print(f"\n[Unknown tau] auto from val | keep_coverage={cfg.known_keep_coverage:.3f} => tau={tau:.4f}")
    else:
        tau = float(cfg.unknown_tau)
        print(f"\n[Unknown tau] manual => tau={tau:.4f}")

    # ========== Stage-2: Known-only testï¼ˆä¸å« injectionï¼‰ ==========
    maxp_te_k, pred_te_k = predict_multiclass(model_type, Xw_te_k, cfg.device, cfg.batch_size)
    print("\n[TEST][Stage-2 Known-Attack Types | Known attack windows only]")
    print("macro_f1=%.4f weighted_f1=%.4f" % (
        f1_score(yt_te_k, pred_te_k, average="macro", labels=list(range(K_attack)), zero_division=0),
        f1_score(yt_te_k, pred_te_k, average="weighted", labels=list(range(K_attack)), zero_division=0),
    ))
    try:
        print("\n[Attack-Type ClassificationReport][Known attack windows only]")
        print(classification_report(yt_te_k, pred_te_k, labels=list(range(K_attack)), target_names=attack_type_set, zero_division=0, digits=4))
    except Exception:
        pass

    # =========================
    # 6) Unknown / æ‹’è¯†æ€»è¯„ä¼°ï¼ˆåœ¨å®Œæ•´ test ä¸Šï¼‰
    # =========================
    # Ground-truth injection windowsï¼ˆä»¥ last-step çš„ type ä¸ºå‡†ï¼‰
    inj_mask = (yb_te == 1) & (np.char.lower(tlast_te.astype(str)) == cfg.unknown_token.lower())

    # Stage-2 åªå¯¹â€œè¢« Stage-1 åˆ¤ä¸º Attackâ€çš„çª—å£åšæ‹’è¯†/å¤šåˆ†ç±»
    attack_pred_mask = pred_te_attack.astype(bool)

    # å¯¹ attack_pred çš„çª—å£è·‘ Stage-2
    Xw_te_for_stage2 = Xw_te[attack_pred_mask]
    if len(Xw_te_for_stage2) > 0:
        maxp_all, pred_all = predict_multiclass(model_type, Xw_te_for_stage2, cfg.device, cfg.batch_size)
    else:
        maxp_all = np.array([], dtype=np.float32)
        pred_all = np.array([], dtype=np.int64)

    # æŠŠ stage2 è¾“å‡ºå›å¡«åˆ°å…¨é‡çª—å£ï¼ˆæœªè¿›å…¥ stage2 çš„è®¾ä¸º -inf / -1ï¼‰
    maxp_full = np.full(len(Xw_te), -1.0, dtype=np.float32)
    pred_full = np.full(len(Xw_te), -1, dtype=np.int64)
    maxp_full[attack_pred_mask] = maxp_all
    pred_full[attack_pred_mask] = pred_all

    pred_is_unknown = attack_pred_mask & (maxp_full >= 0) & (maxp_full < tau)

    # ç»Ÿè®¡ Injection çš„å»å‘ï¼ˆNormal / Unknown / KnownAttackï¼‰
    inj_total = int(inj_mask.sum())
    inj_to_normal = int((inj_mask & ~attack_pred_mask).sum())
    inj_to_unknown = int((inj_mask & pred_is_unknown).sum())
    inj_to_known = int((inj_mask & attack_pred_mask & ~pred_is_unknown).sum())

    print("\n[Unknown Eval][Injection as Unknown]")
    if inj_total == 0:
        print("[WARN] test ä¸­æ²¡æœ‰ injection çª—å£ï¼ˆæŒ‰ last-step type ç»Ÿè®¡ï¼‰ï¼Œè¯·ç¡®è®¤ test.csv æ˜¯å¦åŒ…å« injection")
    else:
        print(f"Injection windows total: {inj_total}")
        print(f"  Injectionâ†’Normal : {inj_to_normal} ({inj_to_normal / inj_total:.2%})")
        print(f"  Injectionâ†’Unknown: {inj_to_unknown} ({inj_to_unknown / inj_total:.2%})")
        print(f"  Injectionâ†’Known  : {inj_to_known} ({inj_to_known / inj_total:.2%})")

    # Unknown ä½œä¸ºâ€œæ­£ç±»â€çš„ P/R/F1ï¼ˆåœ¨å…¨é‡çª—å£ä¸Šï¼‰
    y_unknown_true = inj_mask.astype(np.int64)
    y_unknown_pred = pred_is_unknown.astype(np.int64)
    unk_p = precision_score(y_unknown_true, y_unknown_pred, zero_division=0)
    unk_r = recall_score(y_unknown_true, y_unknown_pred, zero_division=0)
    unk_f1 = f1_score(y_unknown_true, y_unknown_pred, zero_division=0)
    # ä¸€ä¸ªå¯ç”¨çš„ unknown scoreï¼š-maxpï¼ˆmaxp è¶Šä½è¶Šåƒ unknownï¼‰ï¼Œæœªè¿›å…¥ stage2 çš„è®°ä¸º +infï¼ˆæ›´ä¸åƒ unknownï¼‰
    score_unknown = -maxp_full
    score_unknown[~attack_pred_mask] = -0.0
    try:
        unk_auroc = roc_auc_score(y_unknown_true, score_unknown)
    except Exception:
        unk_auroc = float('nan')

    print(f"[Unknown] P={unk_p:.4f} R={unk_r:.4f} F1={unk_f1:.4f} AUROC(score=-maxp)={unk_auroc:.4f}")

    # Known-only å¤šåˆ†ç±»ï¼šåªåœ¨ ground-truth known attack ä¸”æœ€ç»ˆæ²¡è¢«æ‹’è¯†/æ²¡è¢«åˆ¤ normal çš„çª—å£ä¸Šç®—
    known_gt_mask = (yb_te == 1) & (yt_te >= 0)
    known_keep_mask = known_gt_mask & attack_pred_mask & (~pred_is_unknown)
    coverage = float(known_keep_mask.sum() / max(1, known_gt_mask.sum()))

    if known_keep_mask.sum() > 0:
        y_true_known = yt_te[known_keep_mask]
        y_pred_known = pred_full[known_keep_mask]
        known_macro_f1 = f1_score(y_true_known, y_pred_known, average="macro", labels=list(range(K_attack)), zero_division=0)
    else:
        known_macro_f1 = 0.0

    print(f"[Known-only] Macro-F1={known_macro_f1:.4f} | coverage={coverage:.4f}")

    # ç»™ä½ ä¸€ä¸ªæ›´ç›´è§‚çš„ï¼šNormal è¢«è¯¯åˆ¤ä¸º Attack çš„æ¯”ä¾‹
    normal_gt_mask = (yb_te == 0)
    fp = int((normal_gt_mask & attack_pred_mask).sum())
    tn = int((normal_gt_mask & ~attack_pred_mask).sum())
    print(f"[Stage-1 FP] Normalâ†’Attack: {fp} / {fp + tn} ({fp / max(1, fp + tn):.2%})")

    print(f"\n[OK] Saved: {best_bin} | {best_type}")


if __name__ == "__main__":
    main()
